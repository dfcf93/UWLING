Please write a statement of your current academic and future career plans as they relate to the Princeton department to which you are applying.
In doing so, please cite relevant academic, professional, and personal experiences that motivate you to apply for a graduate degree here. 
Your statement should not exceed 1,000 words and must be written in English. Please be sure to review your document before uploading and submitting your application.
Beyond what is apparent from your transcripts, describe your preparation for your proposed program of study, including research projects you have undertaken or in which you have participated, as well as language preparation and other academic training where appropriate.

-Research at RPI
    -TWC mobile app Freshman 2011
    -Basis Tech NRR
    -Neural Network based task recognition
    -Networks of Influence and Diffusion
-Microsoft
    -Effect of Neural Machine Translation as time saving mechanism with software Translation
    -Question answering with MSMARCO
    -Document Ranking with MSMARCO
    -TREC 2019
    -AFIRM 2019
    -AFIRM 2020
    -Reviewer LatinX @ NEURIPS 2019
    -TREC 2020
    -Metrics and applied research as a product to represent true user behavior
    -Exploration in stratified sampling
    -JHU Hackathon 2019
    -College recruiting 2015-2019 focused on diversity
    -Embedding based representation of user intent
-Computational Linguistics @UW
    -Formalizing the academic understanding in neural networks
    -Explore higher level academic classes and research in
    -Language Model grounded word vector representation

Outside of studying I set to read and understand the basis of deep learned methods in NLP by reading all the papers and their citations. Moreover I connected with many of the researchers in my work and masters to explain my hopes and discuss wether a PhD is the right path. The
The desire to do a PhD comes from a confirmation that I want to focus on research and a gain a deep understanding of applied methods in natural language processing.
Based on my current experience I want to explore building large scale language representations but with a focus on data efficiency. Current approaches in NLP have proven to be very successful but are clearly not scalable, models take weeks to create, require a corpus of the whole internet and are difficult to recreate. 
I believe that there is much work to be done on understanding how small we can make datasets and still have the model learn robust representations of langauge. 
Spurred by my own origin of a bilingual background I would be keen to further expand models that work with all langues by default and can have a firm understanding of multilinguality.
